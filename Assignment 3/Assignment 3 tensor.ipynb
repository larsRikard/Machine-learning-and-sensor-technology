{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code source: https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb\n",
    "\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"Report\", \"fig\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression MLP imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, max_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' import torch\\nfrom torch import nn\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom tqdm import tqdm '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\"\"\" import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor csv reading method from \"Hands-On Machine Learning...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_line(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    return tf.stack(fields[:-1]), tf.stack(fields[-1:])\n",
    "\n",
    "def preprocess(line):\n",
    "    x, y = parse_csv_line(line)\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, n_readers=5, n_read_threads=None,\n",
    "                       n_parse_threads=5, shuffle_buffer_size=10_000, seed=42,\n",
    "                       batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths, seed=seed)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size, seed=seed)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for making models and generating plots, stolen from previous solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X_train, y_train, X_test, y_test, model):\n",
    " \n",
    "    y_train_predicted = model.predict(X_train)\n",
    "    y_test_predicted = model.predict(X_test)\n",
    "    \n",
    "    print('--------------------TRAIN SET-------------------------')\n",
    "    print('r2_score = ','%.2f' % r2_score(y_train,y_train_predicted), '(1.0 means perfect fit)')\n",
    "    print('max_error = ','%.2f' % max_error(y_train,y_train_predicted))\n",
    "    print('root_mean_squared_error = ','%.2f' % mean_squared_error(y_train,y_train_predicted, squared=False))\n",
    "    print('--------------------TEST SET-------------------------')\n",
    "    print('r2_score = ','%.2f' % r2_score(y_test,y_test_predicted), '(1.0 means perfect fit)')\n",
    "    print('max_error = ','%.2f' % max_error(y_test,y_test_predicted))\n",
    "    print('root_mean_squared_error = ','%.2f' % mean_squared_error(y_test,y_test_predicted, squared=False))\n",
    "    print(y_train.index[:100])\n",
    "    \n",
    "    return r2_score(y_train,y_train_predicted), r2_score(y_test,y_test_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the training set and the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' fan_prepared_test = num_pipeline.fit_transform(fd_001_test)\\nfan_labels_test = fd_001_test[\"RUL\"].copy() '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "useless_features = ['engine','RUL', 'cycle', 'setting 3', 'sensor 1', 'sensor 5', 'sensor 6', 'sensor 10','sensor 14', 'sensor 16', 'sensor 18', 'sensor 19']\n",
    "\n",
    "fd_001_train  = pd.read_csv('train_FD001.csv')\n",
    "y_train_full = fd_001_train['RUL']\n",
    "X_train_full = fd_001_train.drop(columns=useless_features)\n",
    "\n",
    "fd_001_test = pd.read_csv('test_FD001.csv')\n",
    "y_test = fd_001_test['RUL']\n",
    "X_test = fd_001_test.drop(columns=useless_features)\n",
    "\n",
    "\"\"\" X_mlp_train_full = X_train.copy()\n",
    "y_mlp_train_full = y_train.copy()\n",
    "X_mlp_test = X_train.copy()\n",
    "y_mlp_test = y_train.copy() \"\"\"\n",
    "\n",
    "\"\"\" X_mlp_train, X_mlp_valid, y_mlp_train, y_mlp_valid = train_test_split(\n",
    "    X_mlp_train_full, y_mlp_train_full, random_state=42) \"\"\"\n",
    "\n",
    "\"\"\" fan_prepared_test = num_pipeline.fit_transform(fd_001_test)\n",
    "fan_labels_test = fd_001_test[\"RUL\"].copy() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setting 1</th>\n",
       "      <th>setting 2</th>\n",
       "      <th>sensor 2</th>\n",
       "      <th>sensor 3</th>\n",
       "      <th>sensor 4</th>\n",
       "      <th>sensor 7</th>\n",
       "      <th>sensor 8</th>\n",
       "      <th>sensor 9</th>\n",
       "      <th>sensor 11</th>\n",
       "      <th>sensor 12</th>\n",
       "      <th>sensor 13</th>\n",
       "      <th>sensor 15</th>\n",
       "      <th>sensor 17</th>\n",
       "      <th>sensor 20</th>\n",
       "      <th>sensor 21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>642.680934</td>\n",
       "      <td>1590.523119</td>\n",
       "      <td>1408.933782</td>\n",
       "      <td>553.367711</td>\n",
       "      <td>2388.096652</td>\n",
       "      <td>9065.242941</td>\n",
       "      <td>47.541168</td>\n",
       "      <td>521.413470</td>\n",
       "      <td>2388.096152</td>\n",
       "      <td>8.442146</td>\n",
       "      <td>393.210654</td>\n",
       "      <td>38.816271</td>\n",
       "      <td>23.289705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.500053</td>\n",
       "      <td>6.131150</td>\n",
       "      <td>9.000605</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>0.070985</td>\n",
       "      <td>22.082880</td>\n",
       "      <td>0.267087</td>\n",
       "      <td>0.737553</td>\n",
       "      <td>0.071919</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>1.548763</td>\n",
       "      <td>0.180746</td>\n",
       "      <td>0.108251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.008700</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>641.210000</td>\n",
       "      <td>1571.040000</td>\n",
       "      <td>1382.250000</td>\n",
       "      <td>549.850000</td>\n",
       "      <td>2387.900000</td>\n",
       "      <td>9021.730000</td>\n",
       "      <td>46.850000</td>\n",
       "      <td>518.690000</td>\n",
       "      <td>2387.880000</td>\n",
       "      <td>8.324900</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>22.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>642.325000</td>\n",
       "      <td>1586.260000</td>\n",
       "      <td>1402.360000</td>\n",
       "      <td>552.810000</td>\n",
       "      <td>2388.050000</td>\n",
       "      <td>9053.100000</td>\n",
       "      <td>47.350000</td>\n",
       "      <td>520.960000</td>\n",
       "      <td>2388.040000</td>\n",
       "      <td>8.414900</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>23.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>642.640000</td>\n",
       "      <td>1590.100000</td>\n",
       "      <td>1408.040000</td>\n",
       "      <td>553.440000</td>\n",
       "      <td>2388.090000</td>\n",
       "      <td>9060.660000</td>\n",
       "      <td>47.510000</td>\n",
       "      <td>521.480000</td>\n",
       "      <td>2388.090000</td>\n",
       "      <td>8.438900</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>38.830000</td>\n",
       "      <td>23.297900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>1594.380000</td>\n",
       "      <td>1414.555000</td>\n",
       "      <td>554.010000</td>\n",
       "      <td>2388.140000</td>\n",
       "      <td>9069.420000</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>521.950000</td>\n",
       "      <td>2388.140000</td>\n",
       "      <td>8.465600</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>38.950000</td>\n",
       "      <td>23.366800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>644.530000</td>\n",
       "      <td>1616.910000</td>\n",
       "      <td>1441.490000</td>\n",
       "      <td>556.060000</td>\n",
       "      <td>2388.560000</td>\n",
       "      <td>9244.590000</td>\n",
       "      <td>48.530000</td>\n",
       "      <td>523.380000</td>\n",
       "      <td>2388.560000</td>\n",
       "      <td>8.584800</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>39.430000</td>\n",
       "      <td>23.618400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          setting 1     setting 2      sensor 2      sensor 3      sensor 4  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  20631.000000   \n",
       "mean      -0.000009      0.000002    642.680934   1590.523119   1408.933782   \n",
       "std        0.002187      0.000293      0.500053      6.131150      9.000605   \n",
       "min       -0.008700     -0.000600    641.210000   1571.040000   1382.250000   \n",
       "25%       -0.001500     -0.000200    642.325000   1586.260000   1402.360000   \n",
       "50%        0.000000      0.000000    642.640000   1590.100000   1408.040000   \n",
       "75%        0.001500      0.000300    643.000000   1594.380000   1414.555000   \n",
       "max        0.008700      0.000600    644.530000   1616.910000   1441.490000   \n",
       "\n",
       "           sensor 7      sensor 8      sensor 9     sensor 11     sensor 12  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  20631.000000   \n",
       "mean     553.367711   2388.096652   9065.242941     47.541168    521.413470   \n",
       "std        0.885092      0.070985     22.082880      0.267087      0.737553   \n",
       "min      549.850000   2387.900000   9021.730000     46.850000    518.690000   \n",
       "25%      552.810000   2388.050000   9053.100000     47.350000    520.960000   \n",
       "50%      553.440000   2388.090000   9060.660000     47.510000    521.480000   \n",
       "75%      554.010000   2388.140000   9069.420000     47.700000    521.950000   \n",
       "max      556.060000   2388.560000   9244.590000     48.530000    523.380000   \n",
       "\n",
       "          sensor 13     sensor 15     sensor 17     sensor 20     sensor 21  \n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  20631.000000  \n",
       "mean    2388.096152      8.442146    393.210654     38.816271     23.289705  \n",
       "std        0.071919      0.037505      1.548763      0.180746      0.108251  \n",
       "min     2387.880000      8.324900    388.000000     38.140000     22.894200  \n",
       "25%     2388.040000      8.414900    392.000000     38.700000     23.221800  \n",
       "50%     2388.090000      8.438900    393.000000     38.830000     23.297900  \n",
       "75%     2388.140000      8.465600    394.000000     38.950000     23.366800  \n",
       "max     2388.560000      8.584800    400.000000     39.430000     23.618400  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multi-layer Perceptron</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 hidden layers, Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline_mlp_1 = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline_mlp_1.fit(X_train_full, y_train_full)\n",
    "y_pred = pipeline_mlp_1.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.594817064172354"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 hidden layers, lbfgs optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42, solver='lbfgs')\n",
    "pipeline_mlp_2 = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline_mlp_2.fit(X_train_full, y_train_full)\n",
    "y_pred = pipeline_mlp_2.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.47616185711904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam optimizer with lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42, learning_rate_init=0.0005, max_iter=600)\n",
    "pipeline_mlp_3 = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline_mlp_3.fit(X_train_full, y_train_full)\n",
    "y_pred = pipeline_mlp_3.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------TRAIN SET-------------------------\n",
      "r2_score =  0.65 (1.0 means perfect fit)\n",
      "max_error =  223.69\n",
      "root_mean_squared_error =  40.63\n",
      "--------------------TEST SET-------------------------\n",
      "r2_score =  0.38 (1.0 means perfect fit)\n",
      "max_error =  218.75\n",
      "root_mean_squared_error =  46.59\n",
      "RangeIndex(start=0, stop=100, step=1)\n",
      "--------------------TRAIN SET-------------------------\n",
      "r2_score =  0.67 (1.0 means perfect fit)\n",
      "max_error =  211.51\n",
      "root_mean_squared_error =  39.67\n",
      "--------------------TEST SET-------------------------\n",
      "r2_score =  0.35 (1.0 means perfect fit)\n",
      "max_error =  227.81\n",
      "root_mean_squared_error =  47.48\n",
      "RangeIndex(start=0, stop=100, step=1)\n",
      "--------------------TRAIN SET-------------------------\n",
      "r2_score =  0.66 (1.0 means perfect fit)\n",
      "max_error =  217.51\n",
      "root_mean_squared_error =  40.05\n",
      "--------------------TEST SET-------------------------\n",
      "r2_score =  0.38 (1.0 means perfect fit)\n",
      "max_error =  214.91\n",
      "root_mean_squared_error =  46.47\n",
      "RangeIndex(start=0, stop=100, step=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6619856937750027, 0.379175645112903)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(X_train_full,y_train_full,X_test,y_test, pipeline_mlp_1)\n",
    "test_model(X_train_full,y_train_full,X_test,y_test, pipeline_mlp_2)\n",
    "test_model(X_train_full,y_train_full,X_test,y_test, pipeline_mlp_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recurrent Neural Network</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 15, 50)            5050      \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,151\n",
      "Trainable params: 10,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_rnn = keras.models.Sequential()\n",
    "model_rnn.add(keras.Input(shape=(15,50)))\n",
    "model_rnn.add(layers.SimpleRNN(50, return_sequences=True, activation='relu'))\n",
    "model_rnn.add(layers.SimpleRNN(50, return_sequences=False, activation='relu'))\n",
    "#model_rnn.add(layers.SimpleRNN(50, return_sequences=True, activation='relu'))\n",
    "#model_rnn.add(layers.LSTM(50, return_sequences=False, activation='relu'))\n",
    "model_rnn.add(layers.Dense(1))\n",
    "print(model_rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optim = keras.optimizers.Adam(lr=0.001)\n",
    "metrics = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(loss=loss, optimizer=optim, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\105095~1\\AppData\\Local\\Temp/ipykernel_10752/471415913.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 15, 50) for input KerasTensor(type_spec=TensorSpec(shape=(None, 15, 50), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 15).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"simple_rnn\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 15)\n    \n    Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 15), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\105095~1\\AppData\\Local\\Temp/ipykernel_10752/1403409771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# evaulate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Program Files\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 232, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential\" \"                 f\"(type Sequential).\n    \n    Input 0 of layer \"simple_rnn\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 15)\n    \n    Call arguments received by layer \"sequential\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(None, 15), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "model_rnn.fit(X_train_full, y_train_full, batch_size=batch_size, epochs=epochs, verbose=2)\n",
    "\n",
    "# evaulate\n",
    "model_rnn.evaluate(X_test, y_test, batch_size=batch_size, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
